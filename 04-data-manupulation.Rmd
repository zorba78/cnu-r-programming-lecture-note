
```{r, echo=FALSE, message=FALSE}
rm(list = ls())
require(knitr)
opts_chunk$set(size="footnotesize",
                      comment = NA,
                      highlight = TRUE)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})

hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
opts_chunk$set(tidy.opts=list(blank=FALSE, width.cutoff=80))
options(linewidth = 60)

require(tidyverse)
require(rmarkdown)
require(knitr)
require(kableExtra)
```

# 데이터 관리(Data Management) {#data-manipulation}

```{block2, type="rmdimportant"}
**학습 목표**

- Hadely Weckam이 개발한 데이터의 전처리 및 시각화를 위해 각광받는 tidyverse 패키지에 대해 알아본다
- 데이터를 읽고, 저장하고, 목적에 맞게 가공하고, tidyverse 하에서 반복 계산 방법에 대해 알아본다. 

```


**데이터 분석과정**

1) 데이터를 R 작업환경(workspace)에 **불러오고(import)**, 
2) 불러온 데이터를 **가공하고(data management, data preprocessing)**, 
3) 가공한 데이터를 **분석(analysis, modeling)** 및 **시각화(visualization)** 후,  
4) 분석 결과를 **저장(save)** 및 외부 파일로 **내보낸(export)** 후, 
5) 이를 통해 전문가와 **소통(communicate)**


```{r fig.align='center', echo=FALSE, fig.show='hold', out.width='100%', fig.cap="Data 분석의 과정. @wickham-2016r 에서 발췌"}
knitr::include_graphics('figures/data-science.png', dpi = NA)
```



**R의 데이터 가공(관리) 방법**

1. 기본 R을 활용: 지금까지 배워온 방법으로 분석을 위한 데이터 가공(색인, 필터, 병합 등)


2. **tidyverse** 패키지 활용
   - 직관적 코드 작성 가능
   - 빠른 실행속도


3. **data.table** 패키지 활용(본 강의에서는 다루지 않음)
   - 빠른 실행속도 
   

다양한 통계 함수와 최신 분석에 대한 여러 패키지 및 함수를 R 언어를 통해 활용 가능함에도 불구하고, 타 통계 소프트웨어(SAS, SPSS, Stata, Minitab 등)에 비해 데이터 가공 및 처리가 직관적이지 않고 불편했던 점은 R이 갖고 있던 큰 단점 중 하나임. RStudio의 수석 데이터 과학자인 Hadely Wickham의 tidyverse는 이러한 단점을 최대한 보완했고, 현재는 R을 통한 데이터 분석에서 핵심적인 도구로 자리매김 하고 있음. Tidyverse의 철학은 R 언어의 생태계에 혁신적인 변화를 가져왔을 뿐 아니라 지속적으로 진화하고 있기 때문에 해당 패키지들이 제공하는 언어 형태를 이해할 필요가 있음. 


## Prerequisites {#ch4-prerequi}

### 외부데이터 불러오기 및 저장 {#data-import-export}

```{block2, type="rmdnote"}
R 기본 함수를 이용해서 데이터 저장 파일의 가장 기본적인 형태인 텍스트 파일을 읽고 저장하는 방법에 대해 먼저 살펴봄. Base R에서 외부 데이터를 읽고 저장을 위한 함수는 매우 다양하지만 가장 많이 사용되고 있는 함수들에 대해 살펴볼 것임
```


- 기본 R(base R)에서 제공하는 함수를 이용해 외부 데이터를 읽고, 내보내고, 저장하는 방법에 대해 살펴봄. 
- 가장 일반적인 형태의 데이터는 보통 텍스트 파일 형태로 저장되어 있음, 일반적으로
   - 첫 번째 줄: 변수명
   - 두 번째 줄 부터: 데이터 입력
   
```
id sex age edulev height 
1 Male 65   12 168
2 Female 74 9  145
3 Male 61   12 171
4 Male 85   6  158
5 Female 88 0  134
```

- 데이터의 자료값과 자료값을 구분하는 문자를 구분자(separator)라고 하며 주로 공백(` `), 콤마(`,`), tab 문자(`\t`) 등이 사용됨
- 주로 확장자 명이 `*.txt` 이며, 콤마 구분자인 경우 보통은 `*.csv` (comma separated values)로 저장

```
#titanic3.csv 파일 일부 

"pclass","survived","name","sex","age",
1,1,"Allen, Miss. Elisabeth Walton","female"
1,1,"Allison, Master. Hudson Trevor","male"
1,0,"Allison, Miss. Helen Loraine", "female"
1,0,"Allison, Mr. Hudson Joshua Creighton","male"
1,0,"Allison, Mrs. Hudson J C (Bessie Waldo Daniels)","female"
```



#### **텍스트 파일 입출력** {#text-import-export .unnumbered}


```{block2, type="rmdcaution"}
외부 데이터를 불러온다는 것은 외부에 저장되어 있는 파일을 R 작업환경으로 읽어온다는 의미이기 때문에, 현재 작업공간의 작업 디렉토리(working directory) 확인이 필요.
```

- `read.table()/write.table()`: 
   - 가장 범용적으로 외부 텍스트 데이터를 R 작업공간으로 데이터 프레임으로 읽고 저장하는 함수
   - 텍스트 파일의 형태에 따라 구분자 지정 가능

```{r read-table-proto, eval=FALSE}
# read.table(): 텍스트 파일 읽어오기
read.table(
  file, # 파일명. 일반적으로 폴더명 구분자 
        # 보통 folder/파일이름.txt 형태로 입력
  header = FALSE, # 첫 번째 행을 헤더(변수명)으로 처리할 지 여부
  sep = "", # 구분자 ",", "\t" 등의 형태로 입력
  comment.char = "#", # 주석문자 지정
  stringsAsFactors = TRUE, # 문자형 변수를 factor으로 변환할 지 여부
  encoding = "unknown" # 텍스트의 encoding 보통 CP949 또는 UTF-8
                       # 한글이 입력된 데이터가 있을 때 사용
)
```

- `read.table()` 예시

```{block2, type="rmdnote"}
예시에 사용된 데이터들은 Clinical trial data analysis using R [@chen-2010]에서 제공되는 데이터임.
```


```{r read-table-ex1, error=TRUE}
# tab 구분자 데이터 불러오기
# dataset 폴더에 저장되어 있는 DBP.txt 파일 읽어오기
dbp <- read.table("dataset/DBP.txt", sep = "\t", header = TRUE)
str(dbp)

# 문자형 값들을 factor로 변환하지 않는 경우
dbp2 <- read.table("dataset/DBP.txt", sep = "\t", 
                   header = TRUE, 
                   stringsAsFactors = FALSE)
str(dbp2)

# 데이터 형태 파악
head(dbp)

# 콤마 구분자 데이터 불러오기
# dataset 폴더에 저장되어 있는 diabetes_csv.txt 파일 읽어오기
diab <- read.table("dataset/diabetes_csv.txt", sep = ",", header = TRUE)
str(diab)
head(diab)


# Encoding이 다른 경우(한글데이터 포함): 
# 한약재 사전 데이터 (CP949 encoding으로 저장)
# tab 구분자 데이터 사용
# UTF-8로 읽어오기
herb <- read.table("dataset/herb_dic_sample.txt", sep = "\t", 
                   header = TRUE, 
                   encoding = "UTF-8", 
                   stringsAsFactors = FALSE)
head(herb)

# CP949로 읽어오기
herb <- read.table("dataset/herb_dic_sample.txt", sep = "\t", 
                   header = TRUE, 
                   encoding = "CP949", 
                   stringsAsFactors = FALSE)
head(herb)


```

- `read.table()` + `textConnection()`: 웹사이트나 URL에 있는 데이터를 `Copy + Paste` 해서 읽어올 경우 유용하게 사용
   - `textConnection()`: 텍스트에서 한 줄씩 읽어 문자형 벡터처럼 인식할 수 있도록 해주는 함수

```{r read-table-ex2}

# Plasma 데이터: http://lib.stat.cmu.edu/datasets/Plasma_Retinol 
input1 <- ("64	2	2	21.4838	1	1298.8	57	6.3	0	170.3	1945	890	200	915
76	2	1	23.87631	1	1032.5	50.1	15.8	0	75.8	2653	451	124	727
38	2	2	20.0108	2	2372.3	83.6	19.1	14.1	257.9	6321	660	328	721
40	2	2	25.14062	3	2449.5	97.5	26.5	0.5	332.6	1061	864	153	615
72	2	1	20.98504	1	1952.1	82.6	16.2	0	170.8	2863	1209	92	799
40	2	2	27.52136	3	1366.9	56	9.6	1.3	154.6	1729	1439	148	654
65	2	1	22.01154	2	2213.9	52	28.7	0	255.1	5371	802	258	834
58	2	1	28.75702	1	1595.6	63.4	10.9	0	214.1	823	2571	64	825
35	2	1	23.07662	3	1800.5	57.8	20.3	0.6	233.6	2895	944	218	517
55	2	2	34.96995	3	1263.6	39.6	15.5	0	171.9	3307	493	81	562")

input2 <- ("AGE: Age (years)
	SEX: Sex (1=Male, 2=Female).
	SMOKSTAT: Smoking status (1=Never, 2=Former, 3=Current Smoker)
	QUETELET: Quetelet (weight/(height^2))
	VITUSE: Vitamin Use (1=Yes, fairly often, 2=Yes, not often, 3=No)
	CALORIES: Number of calories consumed per day.
	FAT: Grams of fat consumed per day.
	FIBER: Grams of fiber consumed per day.
	ALCOHOL: Number of alcoholic drinks consumed per week.
	CHOLESTEROL: Cholesterol consumed (mg per day).
	BETADIET: Dietary beta-carotene consumed (mcg per day).
	RETDIET: Dietary retinol consumed (mcg per day)
	BETAPLASMA: Plasma beta-carotene (ng/ml)
	RETPLASMA: Plasma Retinol (ng/ml)")

plasma <- read.table(textConnection(input1), sep = "\t", header = F)
codebook <- read.table(textConnection(input2), sep = ":", header = F)
varname <- gsub("^\\s+", "", codebook$V1) # 변수명 지정

names(plasma) <- varname
head(plasma)

```

- `write.table()`: R의 객체(벡터, 행렬, 데이터 프레임)를 저장 후 외부 텍스트 파일로 내보내기 위한 함수


```{r write-table-proto, eval=FALSE}
# write.table() R 객체를 텍스트 파일로 저장하기
write.table(
  data_obj, # 저장할 객체 이름
  file,  # 저장할 위치 및 파일명  또는 
         # 또는 "파일쓰기"를 위한 연결 명칭
  sep,   # 저장 시 사용할 구분자
  row.names = TRUE # 행 이름 저장 여부
)
```

- 예시

```{r write-table-ex-1}
# 위에서 읽어온 plasma 객체를 dataset/plasma.txt 로 내보내기
# 행 이름은 생략, tab으로 데이터 구분

write.table(plasma, "dataset/plasma.txt", 
            sep = "\t", row.names = F)

```

- 파일명 대신 Windows clipboard 로 내보내기 가능

```{r write-table-ex-2}
# clipboard로 복사 후 excel 시트에 해당 데이터 붙여넣기
# Ctrl + V
write.table(plasma, "clipboard", 
            sep = "\t", row.names = F)
```


- `read.csv()`/`write.csv()`: `read.table()` 함수의 wrapper 함수로 구분자 인수 `sep`이 콤마(`,`)로 고정(예시 생략)


#### R 바이너리(binary) 파일 입출력 {#binary-import-export .unnumbered}

R 작업공간에 존재하는 한 개 이상의 객체들을 저장하고 읽기 위한 함수

- R 데이터 관련 바이너리 파일은 한 개 이상의 객체가 저장된 바이너리 파일인 경우 `*.Rdata` 형태를 갖고, 단일 객체를 저장할 경우 보통 `*.rds` 파일 확장자로 저장

- `*.Rdata` 입출력 함수
   - `load()`: `*.Rdata` 파일 읽어오기
   - `save()`: 한 개 이상 R 작업공간에 존재하는 객체를 `.Rdata` 파일로 저장
   - `save.image()`: 현재 R 작업공간에 존재하는 모든 객체를 `.Rdata` 파일로 저장

```{r im-exp-Rdata-ex}
# 현재 작업공간에 존재하는 모든 객체를 "output" 폴더에 저장
# output 폴더가 존재하지 않는 경우 아래 명령 실행
# dir.create("output") 
ls()
save.image(file = "output/all_obj.Rdata")

rm(list = ls()) 
ls()
# 저장된 binary 파일(all_obj.Rdata) 불러오기
load("output/all_obj.Rdata")
ls()

# dnp, plasma 데이터만 output 폴더에 sub_obj.Rdata로 저장
save(dbp, plasma, file = "output/sub_obj.Rdata")
rm(list = c("dbp", "plasma"))
ls()

# sub_obj.Rdata 파일 불러오기
load("output/sub_obj.Rdata")
ls()
```


- `*.rds` 입출력 함수
   - `readRDS()`/ `saveRDS()`: 단일 객체가 저장된 `*.rds` 파일을 읽거나 저장
   - 대용량 데이터를 다룰 때 유용함
   - `read.table()` 보다 데이터를 읽는 속도가 빠르며, 다른 확장자 명의 텍스트 파일보다 높은 압축율을 보임

```{r im-exp-rds-ex}
# 대용량 파일 dataset/pulse.csv 불러오기
# system.time(): 명령 실행 시가 계산 함수
system.time(pulse <- read.csv("dataset/pulse.csv", header = T))

# saveRDS()함수를 이용해 output/pulse.rds 파일로 저장
saveRDS(pulse, "output/pulse.rds")
rm(pulse); ls()

system.time(pulse <- readRDS("output/pulse.rds"))
```



## Tidyverse {#tidyverse}



- "Tidy" + "Universe"의 조어로 "tidy data"의 기본 설계 철학, 문법 및 데이터 구조를 공유하는 RStudio 수석 과학자인 Hadley Wickham이 개발한 패키지 묶음(번들) 또는 메타 패키지로, 데이터 과학(data science)을 위한 R package를 표방 [@R-tidyverse] 

- 데이터 분석 과정 중 가장 긴 시간을 할애하는 데이터 전처리(data preprocessing, data management, data wrangling, data munging 등으로 표현)를 위한 다양한 함수들을 제공하며, 특히 파이프(pipe) 연산자로 지칭되는 `%>%`를 통한 코드의 간결성 및 가독성을 최대화 하는 것이 tidyverse 패키지들의 특징

- Hadley Wickham이 주창한 [Tidy Tools Manifesto](https://mran.microsoft.com/web/packages/tidyverse/vignettes/manifesto.html)에 따르면, tidyverse가 추구하는 프로그래밍 인터페이스에 대한 4 가지 원칙을 제시

> 1) 기존 데이터의 구조를 재사용
>
> 2) 파이프 연산자를 이용한 최대한 간결한 함수 작성
>
> 3) R의 특징 중 하나인 functional programming 수용
>
> 4) 사람이 읽기 쉬운 프로그램으로 설계


- Tidyverse를 구성하는 주요 패키지(알파벳 순)

> 1) **dplyr**: 가장 일반적인 데이터 가공 및 처리 해결을 위한 "동사"(함수)로 구성된 문법 제공
> 2) **forcat**: 범주형 변수 처리를 위해 Rdml factor와 관련된 일반적인 문제 해결을 위한 함수 제공
> 3) **ggplot2**: 그래픽 문법을 기반으로 2차원 그래픽을 생성하기 위해 고안된 시스템
> 4) **purrr**: 함수 및 벡터의 반복 작업을 수행할 수 있는 도구를 제공
> 5) **readr**: base R에서 제공하는 파일 입출력 함수보다 효율적인 성능을 갖는 입출력 함수로 구성
> 6) **stringr**: 가능한 한 쉬운 방법으로 문자열을 다룰 수 있는 함수 제공
> 7) **tibble**: Tidyverse에서 재해석한 데이터 프레임 형태로 tidyverse에서 다루는 데이터의 기본 형태
> 8) **tidyr**: 데이터를 정리하고 "tidy data"를 도출하기 위한 일련의 함수 제공



```{r fig.align='center', echo=FALSE, fig.show='hold', out.width='100%'}
knitr::include_graphics('figures/tidyverse_packages.png', dpi = NA)
```


- 그 밖에 유용한 tidyverse에 소속되어 있는 패키지

> - **haven**: 타 통계 프로그램(SAS, SPSS, Stata)의 데이터 포멧 입출력 함수 제공
> - **readxl**: Excel 파일 입력 함수 제공
> - **lubridate**: 시간(년/월/일/시/분) 데이터 가공 및 연산 함수 제공
> - **magrittr**: Tidyverse의 문법(함수)를 연결 시켜주는 파이프 연산자 제공. 예전에는 독립적인 패키지였으나 지금은 모든 tidyverse 패키지에 내장되어 있음


## `readr` 패키지 {#readr}

- 기본적으로 \@ref(data-import-export) 절에서 학습했던 `read.table()`, `read.csv()`와 거의 동일하게 작동하지만, 읽고 저장하는 속도가 base R에서 제공하는 기본 입출력 함수보다 월등히 뛰어남. 최근 readr 패키지에서 제공하는 입출력 함수보다 더 빠르게 데이터 입출력이 가능한 feather 패키지 [@R-feather] 제공 

- 데이터를 읽는 동안 사소한 문제가 있는 경우 해당 부분에 경고 표시 및 행, 관측 정보를 표시해줌 $\rightarrow$ 데이터 디버깅에 유용

- 주요 함수^[주요 함수들의 사용방법은 거의 유사하기 때문에 read_csv() 함수에 대해서만 살펴봄]
   - `read_table()`, `write_table()`
   - `read_csv()`, `write_csv()`

- [readr vignette](https://cran.r-project.org/web/packages/readr/vignettes/readr.html)을 통해 더 자세한 예시를 살펴볼 수 있음

```{r read_csv-proto, eval=FALSE}
read_csv(
  file, # 파일 명
  col_names = TRUE, # 첫 번째 행를 변수명으로 처리할 것인지 여부
                    # read.table(), read.csv()의 header 인수와 동일
  col_types = NULL, # 열(변수)의 데이터 형 지정
                    # 기본적으로 데이터 유형을 자동으로 감지하지만, 
                    # 입력 텍스트의 형태에 따라 데이터 유형을 
                    # 잘못 추측할 수 있기 때문에 간혹 해당 인수 입력 필요
                    # col_* 함수 또는 campact string으로 지정 가능
                    # c=character, i=integer, n=number, d=double, 
                    # l=logical, f=factor, D=date, T=date time, t=time
                    # ?=guess, _/- skip column
  progress, # 데이터 읽기/쓰기  진행 progress 표시 여부
)
```

- 예시

```{r read_csv-ex}
# dataset/titanic3.csv 불러오기
titanic <- read_csv("dataset/titanic3.csv")
titanic

# read.csv와 비교
head(read.csv("dataset/titanic3.csv", header = T), 10)

# column type을 변경
titanic2 <- read_csv("dataset/titanic3.csv", 
                     col_types = "iicfdiicdcfcic")
titanic2

# 특정 변수만 불러오기
titanic3 <- read_csv("dataset/titanic3.csv", 
                     col_types = cols_only(
                       pclass = col_integer(), 
                       survived = col_integer(), 
                       sex = col_factor(), 
                       age = col_double()
                     ))
titanic3

# 대용량 데이터셋 읽어올 때 시간 비교
# install.packages("feather") # feather package
require(feather)
system.time(pulse <- read.csv("dataset/pulse.csv", header = T))
write_feather(pulse, "dataset/pulse.feather")
system.time(pulse <- readRDS("output/pulse.rds"))
system.time(pulse <- read_csv("dataset/pulse.csv"))
system.time(pulse <- read_feather("dataset/pulse.feather"))

```


### Excel 파일 입출력 {#import-export-excel}

- R에서 기본적으로 제공하는 파일 입출력 함수는 대부분 텍스트 파일(`*.txt`, `*.csv`, `*.tsv`^[tab separated values])을 대상으로 하고 있음
- **readr** 패키지에서도 이러한 원칙은 유지됨
- Excel 파일을 R로 읽어오기(과거 방법) 
   - `*.xls` 또는 `*.xlsx` 파일을 엑셀로 읽은 후 해당 데이터를 위 텍스트 파일 형태로 내보낸 후 해당 파일을 R로 읽어옴
   - **xlsx** 패키지 등을 이용해 엑셀 파일을 직접 읽어올 수 있으나, Java 기반으로 개발된 패키지이기 때문에 Java Runtime Environment를 운영체제에 설치해야만 작동

- 최근 tidyverse 중 하나인 **readxl** 패키지를 이용해 간편하게 R 작업환경에 엑셀 파일을 읽어오는 것이 가능(Hadley Wickham이 개발...)
   - tidyverse의 한 부분임에도 불구하고 tidyverse 패키지 번들에는 포함되어 있지 않기 때문에 별도 설치 필요
   
#### **readxl** 패키지 구성 주요 함수 {#readxl-funs .unnumbered}

- `read_xls()`, `read_xlsx()`, `read_excel`: 엑셀 파일을 읽어오는 함수로 각각 Excel 97 ~ 2003, Excel 2007 이상, 또는 버전 상관 없이 저장된 엑셀 파일에 접근함
- `excel_sheets()`: 엑셀 파일 내 시트 이름 추출 $\rightarrow$ 한 엑셀 파일의 복수 시트에 데이터가 저장되어 있는 경우 활용
- 예시: 2020년 4월 23일 COVID-19 유병률 데이터 ([Our World in Data](https://github.com/owid/covid-19-data/tree/master/public/data))

```{r read_xlsx-ex, eval=FALSE}
read_xlsx(
  path, # Excel 폴더 및 파일 이름
  sheet = NULL, # 불러올 엑셀 시트 이름
                # default = 첫 번째 시트
  col_names = TRUE, # read_csv()의 인수와 동일한 형태 입력
  col_types = NULL  # read_csv()의 인수와 동일한 형태 입력
)

```



```{r readxls-ex}
# 2020년 4월 21일자 COVID-19 국가별 유별률 및 사망률 집계 자료
# dataset/owid-covid-data.xlsx 파일 불러오기 
# install.packages("readxl")
require(readxl)
covid19 <- read_xlsx("dataset/covid-19-dataset/owid-covid-data.xlsx")
covid19

# 여러 시트를 동시에 불러올 경우
# dataset/datR4CTDA.xlsx 의 모든 시트 불러오기
path <- "dataset/datR4CTDA.xlsx"
sheet_name <- excel_sheets(path)
dL <- lapply(sheet_name, function(x) read_xlsx(path, sheet = x))
names(dL) <- sheet_name

# Tidyverse 에서는? (맛보기)
path %>% 
  excel_sheets %>% 
  set_names %>% 
  map(~read_xlsx(path = path, sheet = .x)) -> dL2


```


### tibble 패키지 {#tibble}

- **readr** 또는 **readxl** 패키지에서 제공하는 함수를 이용해 외부 데이터를 읽어온 후, 확인할 때 기존 데이터 프레임과 미묘한 차이점이 있다는 것을 확인
- 프린트된 데이터의 맨 윗 부분을 보면 `A tibble: 데이터 차원` 이 표시된 부분을 볼 수 있음
- `tibble`은 tidyverse 생태계에서 사용되는 데이터 프레임 $\rightarrow$ 데이터 프레임을 조금 더 빠르고 사용하기 쉽게 수정한 버전의 데이터 프레임

#### tibble 생성하기 {#create-tibble .unnumbered}

- 기본 R 함수에서 제공하는 `as.*` 계열 함수 처럼 `as_tibble()` 함수를 통해 기존 일반적인 형태의 데이터 프레임을 tibble 로 변환 가능

```{r create_tibble-ex1}
head(iris)
as_tibble(iris)

```

- 개별 벡터로부터 tibble 생성 가능
- 방금 생성한 변수 참조 가능
- 문자형 변수가 입력된 경우 데이터 프레임과 다르게 별다른 옵션이 없어도 강제로 factor로 형 변환을 하지 않음

```{r create_tibble-ex2, error=TRUE}
# 벡터로부터 tibble 객체 생성
tibble(x = letters, y = rnorm(26), z = y^2)

# 데이터 프레임으로 위와 동일하게 적용하면?
data.frame(x = letters, y = rnorm(26), z = y^2)

# 벡터의 길이가 다른 경우
# 길이가 1인 벡터는 재사용 가능
tibble(x = 1, y = rep(0:1, each = 4), z = 2)

# 데이터 프레임과 마찬가지로 비정상적 문자를 변수명으로 사용 가능
# 역따옴표(``) 
tibble(`2000` = "year", 
       `:)` = "smile", 
       `:(` = "sad")

```

- `tribble()` 함수 사용: transposed (전치된) tibble의 약어로 데이터를 직접 입력 시 유용

```{r}
tribble(
   ~x, ~y,   ~z,
  "M", 172,  69,
  "F", 156,  45, 
  "M", 165,  73, 
)
```

#### `tibble()`과 `data.frame()`의 차이점 {#diff-tibble-df .unnumbered}

- 가장 큰 차이점은 데이터 처리의 속도 및 데이터의 프린팅 
- tibble이 데이터 프레임 보다 간결하고 많은 정보 확인 가능
- `str()`에서 확인할 수 있는 데이터 유형 확인 가능

```{r}
head(iris)
dd <- as_tibble(iris)
dd

```


## `dplyr` 패키지 {#dplyr}

```{block2, type="rmdnote"}
`dplyr`에서 제공하는 "동사"(함수)로 데이터(데이터 프레임) 전처리 방법에 대해 익힌다. 
```


- `dplyr`은 tidyverse 에서 데이터 전처리를 담당하는 패키지로 데이터 전처리 과정을 쉽고 빠르게 수행할 수 있는 함수로 구성된 패키지임. 

- 데이터 핸들링을 위해 Hadley Wickham이 개발한 `plyr` 패키지를 최적화한 패키지로 C++ 로 코딩되어 성능이 `plyr`에 비해 월등히 우수함. 

- base R에 존재하는 함수만으로도 전처리는 충분히 가능하나, `dplyr`은 아래와 같은 장점을 가짐
   
   a. 파이프 연산자(`%>%`)로 코드의 가독성 극대화
   
   b. 코드 작성이 쉬움
      - 전통적인 R의 데이터 처리에서 사용되는 `[`, `[[`, `$`와 같은 색인 연산자 최소화
      - `dplyr`은 몇 가지 "동사"를 조합하여 사용
   
   c. RStudio를 사용할 경우 코드 작성이 빨라짐 
   
   d. 접근 방법이 SQL 문과 유사함 


- `dplyr`은 초기 데이터 프레임만을 다루지만, `purrr` 패키지를 통해 행렬, 배열, 리스트 등에도 적용 가능


- `dplyr`에서 제공하는 가장 기본 "동사"는 다음과 같음

   - `filter()`: 각 행(row)을 조건에 따라 선택
   
   - `arrange()`: 선택한 변수(column)에 해당하는 행(row)을 기준으로 정렬
   
   - `select()`: 변수(column) 선택
   
   - `mutate()`: 새로운 변수를 추가하거나 이미 존재하는 변수를 변환
   
   - `summarize()` 또는 `summarise()`: 변수 집계(평균, 표준편차, 최댓값, 최솟값, ...)
   
   - `group_by()` : 위 열거한 모든 동사들을 그룹별로 적용
   

- base R 제공 함수와 비교

```{r, echo=FALSE}
`동사(함수)` <- c("filter()", "arrange()", "select()", "mutate()", "summarise()", "group_by()")
`내용` <- c("행 추출", "내림차순/오름차순 정렬", "열 선택", "열 추가 및 변환", "집계", "그룹별 집계 및 함수 적용")
`R base 패키지 함수` <- c("subset()",  
                         "order(), sort()", 
                         "data[, c('var_name01', 'var_name03')]", 
                         "transform()", 
                         "aggregate()", 
                         "") 
tab4_01 <- data.frame(`동사(함수)`, 
                      `내용`, 
                      `R base 패키지 함수`, 
                       check.names = FALSE, 
                       stringsAsFactors = FALSE)
kable(tab4_01,
      align = "lll",
      escape = TRUE, 
      booktabs = T, caption = "dplyr 패키지 함수와 R base 패키지 함수 비교") %>%
  kable_styling(bootstrap_options = c("striped"), 
                position = "center", 
                font_size = 10, 
                full_width = TRUE, 
                latex_options = c("striped", "HOLD_position")) %>% 
  column_spec(1, width = "3cm") %>% 
  column_spec(2, width = "6cm") %>% 
  column_spec(3, width = "6cm") %>% 
  row_spec(1:6, monospace = TRUE)

```


- `dplyr` 기본 동사와 연동해서 사용되는 주요 함수 

   - `slice()`: 행 색인을 이용한 추출 $\rightarrow$ `data[n:m, ]`과 동일
   
   - `distinct()`: 행 레코드 중 중복 항복 제거 $\rightarrow$ base R 패키지의 `unique()` 함수와 유사
   
   - `sample_n()`, `sample_frac()`: 데이터 레코드를 랜덤하게 샘플링 

   - `rename()`: 변수명 변경

   - `inner_join`, `right_join()`, `left_join()`, `full_join` : 두 데이터셋 병합 $\rightarrow$ `merge()` 함수와 유사
   
   - `tally()`, `count()`, `n()`: 데이터셋의 행의 길이(갯수)를 반환하는 함수로 (그룹별) 집계에 사용: `length()`, `nrow()/NROW()` 함수와 유사
   
   - `*_all,`, `*_at`, `*_if`: `dplyr`에서 제공하는 기본 동사(`group_by()` 제외) 사용 시 적용 범위를 설정해 기본 동사와 동일한 기능을 수행하는 함수
   
   

```{block2, type="rmdtip"}
R에서 데이터 전처리 및 분석을 수행할 때, 간혹 동일한 이름의 함수명들이 중복된 채 R 작업공간에 읽어오는 경우가 있는데, 이 경우 가장 마지막에 읽어온 패키지의 함수를 작업공간에서 사용한다. 예를 들어 R base 패키지의 `filter()` 함수는 시계열 데이터의 노이즈를 제거하는 함수이지만, tidyverse 패키지를 읽어온 경우, dplyr 패키지의 `filter()` 함수와 이름이 중복되기 때문에 R 작업공간 상에서는 dplyr 패키지의 `filter()`가 작동을 함. 만약 base 패키지의 `filter()` 함수를 사용하고자 하면 `base::filter()`를 사용. 이를 더 일반화 하면 현재 컴퓨터 상에 설치되어 있는 R 패키지의 특정 함수는 `::` 연산자를 통해 접근할 수 있으며,   `package_name::function_name()` 형태로 접근 가능함. 
```


### 파이프 연산자: `%>%` {#pipe-op}

- Tidyverse 세계에서 tidy를 담당하는 핵심적인 함수

- 여러 함수를 연결(chain)하는 역할을 하며, 이를 통해 불필요한 임시변수를 정의할 필요가 없어짐

- `function_1(x) %>% function_2(y) = function_2(function_1(x), y)`:  `function_1(x)`에서 반환한 값을 `function_2()`의 첫 번째 인자로 사용

- 기존 R 문법과 차이점
   - 기존 R: 동사(목적어, 주변수, 나머지 변수)
   - Pipe 연결 방식: 목적어 `%>%` 동사(주변수, 나머지 변수) 

- 예시 

```{r pipe-ex}
# base R 문법 적용
print(head(iris, 4))

# %>% 연산자 이용
iris %>% head(4) %>% print

# setosa 종에 해당하는 변수들의 평균 계산
apply(iris[iris$Species == "setosa", -5], 2, mean)

# tidyverse의 pipe 연산자 이용
# require(tidyverse)

iris %>% 
  filter(Species == "setosa") %>% 
  select(-Species) %>% 
  summarise_all(mean)

# Homework #3 b-c 풀이를 위한 pipe 연산 적용
# df <- within(df, {
#   am <- factor(am, levels = 0:1, 
#                labels = c("automatic", "manual"))
# })
# ggregate(cbind(mpg, disp, hp, drat, wt, qsec) ~ am, 
#           data = df, 
#           mean)
# aggregate(cbind(mpg, disp, hp, drat, wt, qsec) ~ am, 
#           data = df, 
#           sd)

mtcars %>% 
  mutate(am = factor(vs, 
                     levels = 0:1, 
                     labels = c("automatic", "manual"))) %>% 
  group_by(am) %>% 
  summarise_at(vars(mpg, disp:qsec), 
               list(mean = mean, 
                    sd = sd))

```


### `filter()` {#dplyr-filter}

- 데이터 프레임(또는 tibble)에서 특정 조건을 만족하는 레코드(row) 추출

- R base 패키지의 `subset()` 함수와 유사하게 작동하지만 성능이 더 좋음(속도가 더 빠르다). 

- 추출을 위한 조건은 \@ref(logical) 절 논리형 스칼라에서 설명한 비교 연산자를 준용함. 단 `filter()` 함수 내에서 and (`&`) 조건은 `,`(콤마, comma)로 표현 가능

- `filter()`에서 가능한 불린(boolean) 연산


```{r fig.align='center', echo=FALSE, fig.show='hold', out.width='90%', fig.cap="가능한 모든 boolean 연산 종류: x는 좌변, y는 우변을 의미하고 음영은 연산 이후 선택된 부분을 나타냄."}
knitr::include_graphics('figures/venn-diagram.png', dpi = NA)
```


```{r filter-proto, eval=FALSE}
# filter() 동사 prototype
dplyr::filter(x, # 데이터 프레임 또는 티블 객체
              condition_01, # 첫 번째 조건
              condition_02, # 두 번째 조건
                            # 두 번째 인수 이후 조건들은 
                            # condition_1 & condition 2 & ... & condition_n 임
              ...)
```


- 예시 1: `mpg` 데이터(`ggplot2` 패키지 내장 데이터)

   - `mpg` 데이터 코드북
   
```{r, echo=FALSE}
`변수명` <- c("manufacturer", "model", "displ", 
              "year", "cyl", "trans", "drv", 
              "cty", "hwy", "fl", "class")
`변수설명(영문)` <- c("manufacturer name",
                      "model name",
                      "engine displacement, in litres",
                      "year of manufacture",
                      "number of cylinders",
                      "type of transmission",
                      "the type of drive train, where f = front-wheel drive, r = rear wheel drive, 4 = 4wd",
                      "city miles per gallon",
                      "highway miles per gallon",
                      "fuel type: e = E85, d = diesel, r = regular, p = premium, c = CNG", 
                      "'type' of car")
`변수설명(국문)` <- c("제조사", 
                "모델명", 
                "배기량 (리터)", 
                "제조년도", 
                "엔진 기통 수", 
                "트렌스미션", 
                "구동 유형: f = 전륜구동, r = 후륜구동, 4 = 4륜 구동", 
                "시내 연비", 
                "고속 연비", 
                "연료: e = 에탄올 85, r = 가솔린, p = 프리미엄, d = 디젤, c = CNP", 
                "자동차 타입")
tab4_03 <- data.frame(`변수명`, 
                      `변수설명(영문)`, 
                      `변수설명(국문)`, 
                       check.names = FALSE, 
                       stringsAsFactors = FALSE)
kable(tab4_03,
      align = "lll",
      escape = TRUE, 
      booktabs = T, caption = "gapminder-exercise.xlsx 설명") %>%
  kable_styling(bootstrap_options = c("striped"), 
                position = "center", 
                font_size = 10, 
                full_width = TRUE, 
                latex_options = c("striped", "HOLD_position")) %>% 
  column_spec(1, width = "3cm") %>% 
  column_spec(2, width = "6cm") %>% 
  column_spec(3, width = "6cm") %>% 
  row_spec(1:length(`변수명`), monospace = TRUE)

```



```{r filter-ex-mpg}
# str() 유사한 glimpse() 함수를 통해 데이터 구조 확인
glimpse(mpg)

# 현대 차만 추출
## 기본 문법 사용
# mpg[mpg$manufacturer == "hyundai", ]
# subset(mpg, manufacturer == "hyundai")

## filter() 함수 사용
# filter(mpg, manufacturer == "hyundai")

## pipe 연산자 사용
mpg %>% 
  filter(manufacturer == "hyundai")

# 시내 연비가 20 mile/gallon 이상이고 타입이 suv 차량 추출
## 기본 문법 사용
# mpg[mpg$cty >= 20 & mpg$class == "suv", ]
# subset(mpg, cty >= 20 & class == "suv")

## filter() 함수 사용
# filter(mpg, cty >= 20, class == "suv")

## pipe 연산자 사용
mpg %>% 
  filter(cty >= 20, 
         class == "suv")

# 제조사가 audi 또는 volkswagen 이고 고속 연비가 30 miles/gallon 인 차량만 추출
mpg %>% 
  filter(manufacturer == "audi" | manufacturer == "volkswagen", 
         hwy >= 30)
```

<br/>


- 예시 2: gapminder 데이터

<!-- ```{r filter-ex} -->
<!-- # country_pop 데이터 필터링 -->

<!-- # 데이터 체크 -->
<!-- glimpse(country_pop) -->

<!-- ## 1950 ~ 2020년 까지 데이터 추출 -->
<!-- country_pop %>%  -->
<!--   filter(year >= 1950, year <= 2020) %>%  -->
<!--   summary -->

<!-- ## 1950 ~ 2020년까지 데이터와 인구가 100만 이상인 데이터만 추출 -->
<!-- country_pop %>%  -->
<!--   filter(year >= 1950 & year <= 2020,  -->
<!--          population >= 10^6) %>%  -->
<!--   summary -->

<!-- ## 국가가 한국 또는 일본이고, 2015년도 데이터만 추출 -->
<!-- country_pop %>%  -->
<!--   filter(iso %in% c("kor", "jpn"),  -->
<!--          year == 2015) -->

<!-- ``` -->

### `arrange()`{#dplyr-arrange}

- 지정한 열을 기준으로 데이터의 레코드(row)를 오름차순(작은 값부터 큰 값)으로 정렬

- 내림차순(큰 값부터 작은 값) 정렬 시 `desc()` 함수 이용

```{r, eval=FALSE}
arrange(data, # 데이터 프레임 또는 티블 객체
        var1, # 기준 변수 1
        var2, # 기준 변수 2
        ...)
```

- 예시 1: `mpg` 데이터셋

```{r arrange-ex-mpg}
# 시내 연비를 기준으로 오름차순 정렬
## R 기본 문법 사용
# mpg[order(mpg$cty), ]

## arrange 함수 사용
# arrange(mpg, cty)

## pipe 사용
mpg %>% arrange(cty)


# 시내 연비는 오름차순, 차량 타입은 내림차순(알파벳 역순) 정렬
## R 기본 문법 사용
### 문자형 벡터의 순위 계산을 위해 rank() 함수 사용
mpg_sortb <- mpg[order(mpg$cty, -rank(mpg$class)), ]

## arrange 함수 사용
mpg_sortt <- mpg %>% arrange(cty, desc(class))
mpg_sortt

# 두 데이터 셋 동일성 여부
identical(mpg_sortb, mpg_sortt)

```


### `select()` {#dplyr-select}

- 데이터셋을 구성하는 열을 선택하는 함수

```{r select-proto, eval=FALSE}
select(
  data, # 데이터 프레임 또는 티블 객체
  var_name1, # 변수 이름 (따옴표 없이도 가능)
  var_name2, 
  ...
)
```

```{r select-ex-1}
# 제조사(manufacturer), 모델명(model), 배기량(displ)
# 제조년도(year), 시내연비 (cty)만 추출

## 기본 R 문법 이용한 변수 추출
glimpse(mpg[, c("manufacturer", "model", "displ", "year", "cty")])
# glimpse(mpg[, c(1:4, 8)])
# glimpse(mpg[, names(mpg) %in% c("manufacturer", "displ", "model",
#                         "year", "cty")])

## select() 함수 이용
### 아래 스크립트는 모두 동일한 결과를 반환
# mpg %>% select(1:4, 8)
# 
# mpg %>% 
#   select(c("manufacturer", "model", "displ", "year", "cty"))

mpg %>% 
  select("manufacturer", "model", "displ", "year", "cty") %>% 
  glimpse

```

- R 기본 문법과 차이점

   - 선택하고자 하는 변수 입력 시 따옴표가 필요 없음
   - `:` 연산자를 이용해 선택 변수의 범위 지정 가능
   - `-` 연산자를 이용해 선택 변수 제거

```{r}
# 제조사(manufacturer), 모델명(model), 배기량(displ)
# 제조년도(year), 시내연비 (cty)만 추출
## select() 따옴표 없이 변수명 입력
mpg %>% 
  select(manufacturer, model, displ, year, cty) %>% 
  glimpse

## : 연산자로 변수 범위 지정
mpg %>% 
  select(manufacturer:year, cty) %>% 
  glimpse

## 관심 없는 열을 -로 제외
mpg %>% 
  select(-cyl, -trans, -drv, -hwy, -fl, -class) %>% 
  glimpse

## 조금 더 간결하게 (`:`와 `-` 연산 조합)
mpg %>% 
  select(-cyl:-drv, -hwy:-class) %>% 
  glimpse

### 동일한 기능: -는 괄호로 묶을 수 있음
mpg %>% 
  select(-(cyl:drv), -(hwy:class)) %>% 
  glimpse

```



### `mutate()` {#dplyr-mutate}


### `summarise()` {#dplyr-summarise}


### `group_by()` {#dplyr-group_by}


### dplyr 관련 유용한 함수 {#dplyr-application}

#### `slice()` {#dplyr-slice .unnumbered}

#### `top_n()` {#dplyr-slice .unnumbered}

#### `distinct()` {#dplyr-distinct .unnumbered}

#### `sample_n()/sample_frac()` {#dplyr-sample .unnumbered}

#### `rename()` {#dplyr-rename .unnumbered}

#### **`*_join()`** {#dplyr-join .unnumbered}

#### `inner_join` {#inner-join .unnumbered}

#### `right_join()`, `left_join()` {#left-right-join .unnumbered}

#### `full_join` {#full-join .unnumbered}

#### **Count 관련 함수** {#dplyr-count .unnumbered}

#### `tally()` {#tally .unnumbered}

#### `count()` {#count .unnumbered}

#### `n()` {#n-dplyr .unnumbered}

#### `*_all,`, `*_at`, `*_if` {#dplyr-verb-variant .unnumbered}


### 확장 예제: Gapminder {#ex-gapminder}


```{block2, type="rmdnote"}
**연습 데이터**:  Gapminder 데이터 활용. 각 대륙에 속한 국가의 인구, 경제, 보건, 교육, 환경, 노동에 대한 년도 별 국가 통계를 제공함. [Gapminder](https://gapminder.org)는 스웨덴의 비영리 통계 분석 서비스를 제공하는 웹사이트로, UN이 제공하는 데이터를 기반으로 인구 예측, 부의 이동 등에 관한 연구 논문 및 통계정보, 데이터를 공유함 [@gapminder]. R 패키지 중 `gapminder` [@gapminder-package]는 1950 ~ 2007 년 까지 5년 단위의 국가별 인구(population), 기대수명(year), 일인당 국민 총소득(gross domestic product per captia, 달러)에 대한 데이터를 제공 하지만, 본 강의에서는 현재 Gapminder 사이트에서 직접 다운로드 받은 가장 최근 데이터를 가지고 dplyr 패키지의 기본 동사를 학습함과 동시에 최종적으로 gapminder 패키지에서 제공하는 데이터와 동일한 형태의 구조를 갖는 데이터를 생성하는 것이 목직임. 해당 데이터는 [github 계정](https://zorba78.github.com/cnu-r-programming-lecture-note/dataset/gapminder/gapminder-exercise.xlsx)에서 다운로드가 가능함. 
`gapminder-exercise.xlsx`는 총 4개의 시트로 구성되어 있으며, 각 시트에 대한 설명은 아래와 같음. 
```

```{r, echo = FALSE}
`시트 이름` <- c("region", "country_pop", "gdpcap", "lifeexp")
`설명` <- c("국가별 지역 정보 포함", 
            "국가별 1800 ~ 2100년 까지 추계 인구수(명)", 
            "국가별 1800 ~ 2100년 까지 국민 총소득(달러)", 
            "국가별 1800 ~ 2100년 까지 기대수명(세)")
tab4_02 <- data.frame(`시트 이름`, 
                      `설명`, 
                       check.names = FALSE, 
                       stringsAsFactors = FALSE)
kable(tab4_02,
      align = "ll",
      escape = TRUE, 
      booktabs = T, caption = "gapminder-exercise.xlsx 설명") %>%
  kable_styling(bootstrap_options = c("striped"), 
                position = "center", 
                font_size = 10, 
                full_width = TRUE, 
                latex_options = c("striped", "HOLD_position")) %>% 
  column_spec(1, width = "3cm") %>% 
  column_spec(2, width = "7cm") %>% 
  row_spec(1:4, monospace = TRUE)
```

- Gapminder 예시: `readxl` 패키지 + `%>%`를 이용해 Gapminder 데이터(`gapminder-exercise.xlsx`) 불러오기

```{r}
require(readxl)
path <- "dataset/gapminder/gapminder-exercise.xlsx"
# base R 문법 적용
# sheet_name <- excel_sheets(path)
# gapmL <- lapply(sheet_name, function(x) read_excel(path = path, sheet = x))
# names(gapmL) <- sheet_name

# pope 연산자 이용
path %>% 
  excel_sheets %>% 
  set_names %>% 
  map(read_excel, path = path) -> gapmL

# 개별 객체에 데이터 저장
command <- paste(names(gapmL), "<-", 
                 paste0("gapmL$", names(gapmL)))
for (i in 1:length(command)) eval(parse(text = command[i]))

# check
head(country_pop)
```


## 데이터 변환 {#data-transformation}


## 반복 {#iteration}

